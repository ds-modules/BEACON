{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    "import numpy as np \n",
    "from datascience import *\n",
    "from datetime import date "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b8b93",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis 2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785f2ae8",
   "metadata": {},
   "source": [
    "Now that you have a general idea of the key variables in this table, we will use some of the table and visualization methods from the [Python Reference](https://www.data8.org/sp23/reference/) to analyze any underlying trends in the data. \n",
    "\n",
    "The `exploratorium_emissions` displays information about CO and CO2 emissions at the Exploratorium on various days.\n",
    "It consists the following columns, in order : \n",
    "\n",
    "- `node_id`: Each node is assigned an identification number (the Exploratorium has id 48!)\n",
    "- `local_timestamp`: Pacific Time\n",
    "- `datetime`: Coordinated Universal Time (UTC)\n",
    "- `CO2_ppm`: CO2 emissions in parts per million (ppm) adjusted for standard temperature and pressure\n",
    "- `CO2_QC_level`: quality control level of the CO2 record\n",
    "- `PM_ug/m3`: RH_corrected PM_2.5 concentrations from the Plantower instrument.\n",
    "- `PM_QC_level`: quality control level of the PM record\n",
    "- `CO_ppm`: CO emissions in parts per million (ppm)\n",
    "- `CO_ppm_QC_level`: The quality control level of the CO record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratorium_emissions = Table.read_table('exploratorium_bays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratorium_emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f4941",
   "metadata": {},
   "source": [
    "Looking at the `co2_ppm` column, there isn't much change in the CO2 emissions at the Exploratorium. Take a look at the `co_ppm` column for information about CO emissions. There is a good spread to our data! Let's focus on trends in CO emissions and the respective time/date this data was collected from the Exploratorium Bay. Ignore the code below, we are just cleaning up the data above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de34f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "co_emissions = exploratorium_emissions.drop(2, 3, 4, 6,7, 8, 9, 10).sort('co_ppm', descending = True)\n",
    "\n",
    "#Splitting dates and times for local timestamp\n",
    "date_time = [x.split(' ') for x in co_emissions.column(\"local_timestamp\")]\n",
    "dates = np.array([item[0] for item in date_time])\n",
    "times = np.array([item[1] for item in date_time])\n",
    "table1 = Table().with_columns(\"local_timestamp\", co_emissions.column(\"local_timestamp\"),'Date', dates,  'Time', times)\n",
    "\n",
    "#Splitting dates and times for UTC timestamp\n",
    "date_time1 = [x.split(' ') for x in co_emissions.column(\"datetime\")]\n",
    "dates1 = np.array([item[0] for item in date_time1])\n",
    "times1 = np.array([item[1] for item in date_time1])\n",
    "table2 = Table().with_columns(\"datetime\", co_emissions.column(\"datetime\"),'Date1', dates,  'Time1', times)\n",
    "\n",
    "#joining two tables by date, since columns are the exact same\n",
    "tables_merge = table1.join('Date', table2, 'Date1')\n",
    "\n",
    "#Creating new emissions table, with separated dates and times \n",
    "co_emissions = co_emissions.join('local_timestamp', tables_merge).drop('local_timestamp', 'datetime_2', 'datetime')\n",
    "emissions = co_emissions.column('co_ppm')\n",
    "co_emissions = Table().with_columns('Date', co_emissions.column(1), 'Pacific Time', co_emissions.column(2), 'Universal Time', co_emissions.column(3), 'CO_Emissions', emissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_emissions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb168b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff1878aa",
   "metadata": {},
   "source": [
    "Ignore this code below. It cleans the data frame a little more, and makes it more understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021b46e",
   "metadata": {},
   "source": [
    "We now have a table showing us the carbon monoxide emissions at different times and dates at the Exploratorium Bay. Here are our key features : \n",
    "\n",
    "- `local_timestamp`: Pacific Time\n",
    "- `datetime`: Coordinated Universal Time (UTC)\n",
    "- `CO_ppm`: CO emissions in parts per million (ppm)\n",
    "- `CO2_ppm`: CO2 emissions in parts per million (ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c17c08",
   "metadata": {},
   "source": [
    "We have our table, now lets get to visualizing ! In this section, we will use two key visualizations : \n",
    "1. Scatterplot - we will use the [`.scatter()`](https://www.data8.org/sp23/reference/) method\n",
    "2. Histogram - we use the [`.hist()`](https://www.data8.org/sp23/reference/) method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e7426",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "You may be wondering how to decide between two visualizations when trying to represent your data. For the two visualizations mentioned before, you should follow the following guidelines: \n",
    "\n",
    "   1. Use **scatter plots** to visualize non-sequential numerical data, and if you are looking for associations\n",
    "   </br>\n",
    "   2. Use **histograms** to visualize the distribution of a **single *numerical variable***\n",
    "   </br>\n",
    "    \n",
    "   3.Optionally, although we won't be using it in this exercise, you can use **bar chart** (using [`.barh()`](https://www.data8.org/sp23/reference/)) to visualize the ditribution of a **single *categorical variable***\n",
    "      </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cabc61",
   "metadata": {},
   "source": [
    "create scatter plots "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4babd5b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "When reading the scatter plot, take note of the following:\n",
    "\n",
    "   1. What variable is on the x - axis ? y - axis ?\n",
    "   2. Are the variables scaled differently ? \n",
    "   3. Is there any association between the two varaibles ? (positive, negative, no association)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4c342",
   "metadata": {},
   "source": [
    "create histograms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224e6f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "When reading the histogram, take note of the following:\n",
    "    \n",
    "   1. The horizontal axis will **always** be numerical: drawn to scale, no gaps\n",
    "   2. The area of the bars is proportional to the percent of individuals from the entire sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e5a153",
   "metadata": {},
   "source": [
    "further analysis, answer questions about trends "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
